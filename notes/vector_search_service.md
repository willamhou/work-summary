# 向量检索

## 常见场景

* 以图搜图
* 视频检索
* 生物特征检索
  * 声纹特征
  * 指纹特征
* 各种embedding召回
  * item embedding
  * graph embedding
  * word embedding

## 本质问题

* 海量数据

* 高纬数据

* 解释

  * 内存占用

    ​	在深度学习的场景下, 各种实体都被表征为稠密向量. 比如在NLP中, 一个词向量可以表示成一个256维的矩阵. 

    ​	那一个词向量占的大小是 4（float浮点数） * 256 = 1024 bytes = 1K

    ​	那百万数据集合的占用的内存就是 100 0000 * 1K / 1024 ≈ 1G

    ​	那亿级别的数据集合占用内存就约等于 100G

  * 线性查找

    ​    假设在百万数据集里查找 top200的向量的精确解耗时约为200ms

    ​    那么在亿级的数据下就是100 * 200ms, 耗时远远大于推荐、搜索和广告场景下能承受的延时

* 目标

  * 减少内存占用
  * 减少搜索时间同时topk的精度下降的不厉害

* 向量检索本质

  * 从全空间切分到子空间进行搜索, 减少搜索范围
  * 提前计算好距离差值, 减少高维度向量的计算

* 算法库

  * Annoy
    * 基于树的向量检索库,
    * 特点
      * 不断切分二维平面最多形成二叉树
      * 为了提升精度构建了可以构建多颗二叉树
      * 搜索邻近的两个leaf节点
      * 不存储原始向量
      * 适用于百万数量级的数据
  * Faiss
    * 基于乘积量化的向量检索库
    * 特点
      * 乘积量化压缩内存占用, 不存储原始向量
      * 倒排索引切分子空间, 减少搜索空间
      * 支持动态增删灵活
      * 适用于亿数量级的数据

  ## 向量检索服务

  为了整个服务足够简单, 暂时不考虑向量的增删改. 同时将向量检索服务拆分成两个部分

  * 在线向量检索服务
  * 离线索引构建服务

* 单点向量检索服务

  * 在线向量检索服务
    * 主线程 --- 负责向量检索, 快速返回topk
    * 副线程 --- 负责监听新索引文件
  * 离线索引构建服务
    * 向量数据同步
    * 向量索引构建
    * 向量索引同步

* 高可用检索服务

  * 在线向量检索服务
    * 主线程 --- 负责向量检索, 快速返回topk
    * 副线程 --- 负责监听新索引文件, 将索引文件checkSum回写到离线索引构建服务
  * 离线索引构建服务
    * 向量数据同步
    * 向量索引构建
    * 向量索引同步
    * 在线节点索引数据一致性检查

* 集群检索服务

  * 在线索引proxy层
    * 向各个节点发送向量检索Top K请求
    * 对各个节点检索返回进行归并处理, 返回最终Top K
  * 在线索引集群
    * 一个集群由多个Node组成
      * 每个Node由多个高可用节点组成, proxy到Node的高可用节点之间通过负责均衡实现流量分发
  * 离线索引构建服务
    * 向量数据分片, 将数据划分到不同的Node节点
    * 分片向量数据索引生成
    * 分片向量数据索引同步
    * 分片向量索引Nod数据一致性检查