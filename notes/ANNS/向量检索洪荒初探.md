# 向量检索:洪荒初探

## 写在前面

* 初衷

  写一些关于向量检索文章的念头徘徊在心里已经很久了，但是囿于各种事情和惧怕贻笑大方的情形，始终没有动笔。

  这段时间想来: 纸上得来终觉浅，绝知此事要躬行。与其犹犹豫豫，不如先行动起来，写出来，放出来，同各位朋友互相切磋、取得进步。

* 结构

  * 概要介绍(本篇)
  * LSH简析
  * Annoy及其代码简析
  * Faiss及其代码简析
  * HNSW及其代码简析
  * 新论文简析
  * 向量检索服务化浅谈
  * 向量检索算法优化畅想

## 起源与概念

在深度学习的浪潮席卷下，语音、图像、文本、时间序列、用户行为特征都可以经过深度学习网络的映射变成一组实数表示，这组实数表示就被叫做特征向量。

在上述各个业务场景中，都存在对这些向量集合做检索的需求.  然而实际的业务场景要比我们想象的更复杂。

## 面临的挑战

* 海量数据
  * 在笔者常见的场景中向量特征数据大概是百万到千万的级别
  * 但在很多大体量的公司，向量特征数据大概是亿到百亿甚至更高的级别
* 高维度数据
  * 针对不同的业务场景，向量特征的维度有所不同。以NLP为例，目前常用的Bert是768维
* 高召回率
  * 线性查找: 假设向量维度为d, 数据集合规模为N. 如果我们采用线性查找方式去精确搜索, 整体的时间复杂度是O(Nd).
  * 向量检索实际上是近似搜索，那需要保证召回的准确率不断逼近线性查找的100%，通常的要求在95%以上.
* 高性能
  * 从海量和高纬度数据来看，线性查找的时间会随着数据维度和规模的增大而恶化
  * 在使用向量检索后，期望整个向量检索的时延在毫秒级别

## 目标与本质

从面临的挑战和硬件系统资源来看，我们需要达成两个目标

* 快与准
  * 较低的搜索延时与较高的Top N的召回率的平衡
* 内存占用少
  * 假设特征向量表示为256维度的矩阵, 那么一个特征向量的大小就是1K, 百万集合就是1G, 亿级别集合就是100G.  从硬件资源来看，我们需要降低内存占用

向量检索的本质主要是2点

* 空间划分: 从全空间搜索，到子空间搜索，减少搜索范围
* 提前计算好距离差值,  减少高维度计算

## 常见算法

* 基于哈希的方法
  * LSH
* 基于树的方法
  * Annoy
  * KDTree
* 基于矢量量化的方法
  * PQ
  * OPQ
* 基于图的方法
  * HNSW

## 业务场景

* 以图搜图
* 视频检索
* 文本召回
* 生物特征检索

## 后记

本文是浅淡向量检索的第一篇文章，希望同各位朋友多多交流，其中不免疏漏之处，希望各位予以指正。