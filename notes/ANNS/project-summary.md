# 项目总结

## 智能信息抽取 -- ATM

* 项目简要介绍

  * 对用户query进行分析, 抽取相关实体信息(业务字段实体和普通实体), 最终形成可以被用做SQL查询的结果
  * 业务字段实体:保险行业相关字段 比如险种、保险业务指标
  * 普通实体: 时间、地点、金额、吨位等等实体, 最终映射到业务字段

* 项目场景描述:

  * 典型的低频读场景, 对准确率要求极高
  * 每周访问量几千, 峰值QPS不到10

* 项目成绩

  * 测试环境16 core 32G 100QPS
  * 准确率:整句准确率80% 实体识别准确率90%
  * 前期:规则+NER识别以自己实现为主 --- hard code
  * 后期:feature产品负责规则和实体识别

* 项目主要功能点

  * 文本分类

    * 业务与非业务query区分
      * 非业务query (寒暄): 约为1300句
      * 业务query: 线上积累 + 业务手工模拟 ---- 3000-4000句
      * 实现方法
        * 最早的版本:简单的文本二分类模型
        * 线上版本:基于TFIDF的分类比较
    * 业务类型区分
      * 通过query判断业务类型
      * 实现方法
        * 关键字检查
        * 业务规则逻辑

  * 兜底识别

    * 相当于客服领域的敏感词识别
    * 先将query分词, 然后利用关键字匹配的方式进行识别
    * 进化:后期准备使用前缀字典树的方法完成匹配

  * 字段识别

    * 先将query分词, 然后利用NER+规则识别通用实体. 利用字典+规则识别保险字段专用实体

    * 遇到的问题

      * 实体同业务含义关联

        * 定义业务字段优先级
        * 利用业务字段规则进行区分

      * 一值多槽

        * 举例:我想看直拓客户数目 --- 这里直拓是保险行业专业用语, 可能是业务渠道也可能是新渠道大类
        * 解决方法:
          * 在不同业务字段下出现相同枚举值则利用业务字段优先级来判断
          * 利用历史数据词频填充到对应的业务字段上

      * 一槽多值

        * 举例:18年四季度，未来三个月内车险保单仍有效的客户首次购买了安行宝且年龄大于32岁的客户的保费分布

          险种槽位有两个实体:车险和安行宝

          时间槽位有两个实体:18年四季度 和 未来三个月内

        * 解决方法:

          * 利用业务规则做处理
          * 利用历史数据, 词频信息将其填充到可能性最大的槽位上

      * 层级问题

        * 举例:我要看朝阳支公司车险业务二科的客户数
        * 分析: 一般是总公司、分公司、支公司、中支公司这几个层级, 在历史任务中和用户query中, 一般到支公司就为止了.
        * 解决办法: 直接cut掉支公司以下层级的识别
        * 举例:我要看上海分公司静安支公司的客户数
        * 

      * 地点识别问题

        * 部分地名在通过无法通过NER识别,例子:我要看连云港客户数, 连云港被识别成了名词~~
        * 类似:豫皖苏、江浙沪这种缩写~同样也无法识别的
        * 解决办法:构造一个高频的地点词典~直接利用地点召回

      * 时间识别问题

        * 问题: 无法识别节日类信息, 类似从xx日期到xx日期的同样也无法识别
        * 解决办法:
          * 将常见节日类做成字典做关键字匹配, 匹配到就直接对应年份的节日区间
          * 进行句式模板的总结, 利用正则表达式进行处理
    
      * 单位识别问题
    
        * 问题:无法识别xx单位以上,xx单位以下, 从xx到xx单位, xx-xx等句式. 单位可以是吨、元、升等等
        * 解决办法
          * 进行句式模板的总结, 利用正则表达式进行处理
          * 先利用句式提出关键部分,然后再判断单位
    
    * 项目当前问题
    
      * 只有在线部分的识别解析过程, 没有形成一个数据收集、数据分析的闭环
      * 历史数据不符合用户问句的形式, 叫难利用起来
      * 数据运营的粗放式管理
      * 规则可复用能力较差

## 多机器人架构

* 项目简要介绍

  * 不同部门不同业务都有自己的机器人和知识库,无法做到复用
  * 在不对知识库做改造的情况下, 做到不同业务不同部门间的知识库可以复用

* 项目场景描述

  * 智能客服的场景是典型的读多写少的场景
  * 目前已经上线的两个业务在没有接入全部渠道的情况下的QPS峰值约为20-30.

* 项目成绩

  * 实现了策略式和向量检索投票式的意图路由方案
  * 整体意图路由的准确率在93%左右~~7%的会误判

* 项目主要功能点

  * 策略式路由

    * 在逻辑上定义上了主知识库和从知识库,
    * 当渠道进入后, 首先直接进入主知识库获取最优答案; 如果不是直接回答;则进入从知识库
    * 当分别从主知识库和从知识库获得答案后, 做用户query和主库返回、从库返回的相似度检测
    * 根据相似度检测的结果作为最终的答案返回
    * 典型应用: 上交所 (证券公司知识库 + 证券行业知识库)、江苏银行(电话银行知识库 + 手机银行知识库)

  * 向量检索式路由 (建立在主知识库和从知识库的知识区分比较明显的情况下)

    * 在线检索模块
      * 主线程负责向量检索, 然后根据向量检索的topk(一般取20-30), 来投票算择主知识库和从知识库.当主知识库和从知识库接近时, 则选择策略式路由
      * 副线程负责监听词向量模型、向量索引文件、问句知识库映射表
    * 离线生成模块
      * 定时同步各个知识库的标准问和相似问
      * 生成词向量模型、向量索引文件生成、和问句知识库映射表
      * 将词向量模型、向量索引文件和问句知识库映射表利用SCP同步到各个在线检索模块的节点

  * 存在问题点

    * 纯策略式的由于会多次请求从知识库, 会给从知识库的数据统计带来困扰.多次请求同时消耗网络IO~~从而使得时间请求时间变长

    * 向量检索式的问题

      * 离线生成模块
        * 各部分数据同步到各个节点的时候没有做最终的一致性检查, 导致各个节点存在数据不一致的可能
        * 当前知识库请求没有增量接口, 只有全量接口, 导致每次请求只能进行全量同步~~不能进行增量同步
      * 在线检索模块
        * 每个节点的在线检索模块都需要加载词向量模型、向量索引文件和问句知识库映射表
        * 随着知识库的增加词向量模型会逐渐变大~~增加各个节点的内存占用
      * 解决办法:
        * 离线生成模块增加一个数据一致性的校验, 各个在线模块加载完毕后发送checkSum到离线生产模块完成一致性校验
        * 离线生成模块词向量模型生成后, 将对应的词向量写入到Redis中
        * 在线检索模块不在加载词向量模型, 通过增加一次网络耗时直接到Redis中查询~~
      * 后续演进
        * 由主+单从知识库复用做到主+多从知识库复用
        * 由向量检索的投票式选择引入到文本分类的模型式选择
        * 将寒暄库的知识扩展到知识库中,增加容错性
        * 将向量检索部分单独抽离形成一个可复用的中间件

      

## 智能客服

* 产品场景
  * 智能客服在线问答
  * 外呼
    * 催收
    * 分期
  * IVR语音导航
  * 坐席助手
* 产品架构
  * web知识库管理
    * 知识库管理 增删改查
    * 数据分析与报表
    * FAQ发现、聚类分析及歧义优化
  * 在线问答服务
    * adaptor (限流、鉴权、敏感词、日志)
    * smu 会话管理层 (session存储、缓存访问、pmu访问、情感服务处理、rerank)
    * rbu (子bot访问)
    * qrw (分词、词权重、句法树、实体识别) doubel buffer全量更新
    * pmu (模型打分、embedding生成) (离线服务推送更新)
    * faiss (向量召回和倒排召回) (离线服务推送更新)
    * l3 计算编辑距离、共有词、proximity、词频等NLP特征
  * 离线服务
* 项目业绩
  * adaptor接入层负责人
  * 完成了限流、敏感词、流水等功能开发
  * 设计了AnswerManger模块, 实现答案和doc分离管理
    * 提供两个接口, 读取和写入
    * 将Answer缓存到Redis中
    * 将Answer直接从Redis中读取
* Bot问题
  * QPS太低
  * faiss部分存在数据不一致的问题
  * 内部协议过于复杂
  * 子Bot (FAQ、Chat、KB和Task之间的耦合太严重), 如果同时挂载相当于请求4次~~增加耗时
  * 知识库同在线服务、离线服务耦合、可以做到知识库复用
  * query和answer分离
* 解决方案
  * 构建统一知识库~~将知识库和在线问答服务、离线数据发布的服务解耦
  * 前置意图分类模型, 由意图模型来判断应该路由到哪个子Bot~~类似于阿里小蜜的架构
  * doc和answer分离, 避免answer和doc的多次传递~内部只需要传递ID即可~~使用的使用利用ID去搜索对应的doc
  * 召回模块简化 ---- 向量检索和更新分离; 向量检索和倒排共存即可~~增加add、delete管理避免上锁影响性能





### 问题

* 当前团队规模及技术方向
* 当前业务场景下的营收、增长率和目标
* 当前业务场景下的QPS
* 独立开锅吃饭还是只是负责某个方向
* 场景下遇到哪些挑战