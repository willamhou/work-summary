

# Redis

## Redis  5种基础数据结构

* 字符串 (string)

  编码

  * 整数值  --- int
  * 字符串值且字符串长度<=39个字节 --- embstr
  * 字符串值且字符串长度大于39个字节 --- raw, 利用sds保存
    * sds 采用预分配冗余空间的方式来减少内存的频繁分配.sds的分配的内存空间capacity一般要高于实际字符串长度len
    * 当sds字符串长度小于1MB的时候, 扩容是加倍扩容. 当sds字符串长度大于1MB的时候, 每次只扩容1MB空间
    * 字符串长度最大为512M

* 列表 (list)

  编码

  * ziplist约束
    * 列表对象保存的所有字符串元素的长度都小于64字节
    * 列表对象保存的元素数量小于512个
    * 不能满足上述两个条件的使用linkedList编码
  * linkedlist
    * 双向list

  可以用来做异步队列使用, 将需要延后处理的任务结构体序列化存储成字符串, 存储到Redis列表中. 另外一个线程从这个列表中轮询数据进行处理.

* 字典 (hash)

  编码

  * ziplist约束

    * 哈希对象保存的所有键值对的键和值的字符串长度都小于64字节
    * 哈希对象保存的键值对数量小于512个

  * hashtable

    * 索引计算

      ~~~C++
      hash = dict->type->hashFunction(key)
      
      index = hash & dict->ht[x].sizemask; // sizemask 总是等于哈希表的size - 1
      ~~~

    * 键冲突利用链地址法来解决冲突, 新节点总是直接插入到表头位置

    * rehash

      * 采用了渐进式rehash的策略, 是为了避免直接rehash过程中, hashtable键值对数量过大阻塞服务.

      * 哈希表的扩容与收缩

        * 服务没有执行持久化操作且负载因子大于等于1, 执行扩容
        * 服务有执行持久化操作且负载因子大于等于5, 执行扩容

        ~~~C++
        load_factor = ht[0].used / ht[0].size
        ~~~

        * 负载因子小于0.1的时候, 执行收缩操作

      * 渐进式rehash的过程中, 字典的删除、更新和查找会同时在2个哈希表中进行, 而新添加的键值对一律会被保存到ht[1]中,这一操作保证了ht[0]中的键值对只减不增, 并随着rehash的执行逐渐变成空表

* 集合 (set)

  编码

  * intset约束
    * 集合对象保存的所有元素值都是整数值
    * 集合元素对象保存的元素数量不超过512个(上限512可以修改)
  * hashtable

* 有序集合 (zset)

  编码

  * ziplist约束条件

    * 有序集合保存的元素数量小于128个
    * 有序集合保存的所有元素的的长度都小于64字节

  * skiplist

    * 使用zset有序集合实现, zset包含一个跳表和一个字典

      ~~~c++
      typedef struct zset {
          dict *dict;
          zskiplist *zsl;
      } zset;
      ~~~

    * 字典的键保存了元素的成员, 值保存了元素的分值. 提供了O(1)查找给定成员分值的能力

    * 跳表的object属性保存了元素的成员, 而score保存了元素的分值,提供了范围查找的能力

    * 字典和跳跃表通过指针来共享元素的成员和分值, 因此不会产生重复的成员或者分值,也不会因此浪费内存

  

## Redis持久化策略

默认支持如下两种持久化策略. 由于AOF的更新频率比RDB的更新频率高, 在开启了AOF持久化的功能时,使用AOF持久化. 否则, 使用RDB持久化.

* RDB持久化

  * SAVE 阻塞服务器进程, 直到RDB文件创建完毕

  * BGSAVE 派生出子进程,然后由子进程负责创建RDB文件, 父进程继续处理请求

    * BGSAVE执行期间, 客户端发送的SAVE和BGSAVE命令都会被拒绝, 防止数据竞争
    * BGSAVE与BGREWRITEAOF命令会被延迟到BGSAVE执行完成以后在执行
    * 如果BGREWRITEAOF命令正在执行,则客户端发送的BGSAVE命令会被拒绝

  * 生成RDB文件的时候, 已经过期的键不会被保存到新创建的RDB文件中.

  * 服务器载入RDB文件的时候, 会一直处于阻塞状态,直到载入工作完成为止. 

    * 主服务器载入时, 过期的键不会被载入
    * 从服务器载入时, 无论过期还是不过期,都会被载入. 但是主从服务器进行数据同步的时候,从服务器的数据会被清空.因此过期键对从服务器没有影响

  * 自动间隔性保存

    * redis允许用户通过配置设置服务器save选项,让服务器间隔执行一次BGSAVE命令

      ~~~c++
      save 900 1
      save 300 10
      save 60 10000
      ~~~

* AOF持久化

  * 命令追加

    * 写入aof缓冲区, 是一个sds字符串

  * 文件写入和同步

    * 服务器在每一个事件循环结束前, 调用flushAppendOnlyFile函数,考虑是否将aof_buf中的内容写入和保存到AOF文件中
      * always  --- 将aof缓冲区所有内容写入并同步到AOF文件
      * everysec --- 将aof缓冲区内容写入到aof文件, 如果上次aof文件的时间距离现在超过1s, 再次对AOF文件进行同步.同步操作由专门的线程
      * no --- 将aof缓冲内容写入到aof文件, 但是不对AOF文件进行同步,何时同步由操作系统决定.

  * AOF重写

    AOF持久化是通过保存被执行的命令来记录数据库状态的.随着时间的流逝, AOF的内容会越来越多,体积会越来越庞大.

    AOF重写可以创建一个新的AOF文件来替代现有的文件,新旧两个文件保存的数据库状态相同.但新的AOF文件不会包含浪费空间的冗余命令,要比旧文件少的体积少很多.

    原理

    * AOF重写不需要对现有的AOF文件进行任何读取、分析或者写入操作.通过读取当前服务器当前的数据库状态来实现的

    * 首先冲数据库中读取键现在的值, 然后用一条命令去记录键值对,代替之前记录这个键值对的多条命令

  * AOF后台重写

    * 子进程进行AOF重写工作
    * 利用AOF重写缓冲区保证子进程和父进程的数据一致性. 父进程执行客户端发送完的命令后,将执行后的命令写入AOF缓冲区, 将执行后的写命令写入AOF重写缓冲区.
    * 子进程完成AOF重写操作后,发送信号父进程.父进程调用信号处理函数,并完成以下工作
      * 将AOF重写缓冲区的内容写入AOF文件,AOF文件中保存的数据库的状态同数据库状态一致
      * 对新的AOF文件进行改名,原子化的替换旧的AOF文件

  * AOF过期键的处理

    * AOF重写过程中已过期的键不会被写入到AOF文件中
    * AOF写入过程中,如果一个过期键没有被删除不会对AOF有任何影响;如果被删除,则会被追加一个命令显式删除.

##  Redis过期键策略

过期键的处理策略一共有三种

* 定时删除
  * 设置过期键的时候,创建一个定时器,让定时器在键的过期时间删除,立即执行删除操作
  * 内存友好,但是cpu不友好. 在过期键数量较多的情况下, 删除过期键的行为会占用较多的cpu时间, 会对系统的响应时间和吞吐量造成影响.
* 惰性删除
  * 放任过期键不管.但是每次从键空间获取键的时候,都判断其是否过期.过期删除,否则返回该键
  * cpu友好,内存不友好.会有大量过期键占用内存空间,存在内存泄漏的风险
* 定期删除
  * 定时删除和惰性删除的折中,难点在于确定删除操作的执行时间和频率

Reids中采用了定期删除和惰性删除这两种策略,通过两种策略的配合使用,在合理使用cpu时间和避免浪费内存空间中取得平衡.

默认每秒进行10次过期扫描,扫描时间的上限不超过25ms.

* 惰性删除的实现
  * db.c/expireIfNeeded函数对键的过期状态进行检查
* 定期删除的实现
  * redis.c/activeExpireCycle函数每次运行时,都从一定数量的数据库中取出一定数量的随机键进行检查,并删除其中的过期键
  * 全局变量current_db会记录当前activeExpireCycle的处理进度, 下一次调用时按照上一次的进度进行处理
  * 随着activeExpireCycle的不断执行所有的数据库都会被检查一遍,current_db会被重置为零,并开始新的一轮检查.
* 从节点的过期策略
  * 从节点不会进行定期扫描, 从节点对于过期键的处理是被动.主节点在key到期的时候会在AOF文件中增加一条del指令,同步到所有从节点.
  * 主从节点的指令是异步的,所以如果主节点的del指令没有及时同步到从节点就会出现主从数据不一致的情况.

## Redis内存淘汰策略

当Redis内存超出物理内存限制的时候, 内存的数据会与磁盘产生频繁交互导致Redis服务性能下降. 为了避免这种情况, Redis提供了配置参数maxmemory来限制内存超出期望大小.

当实际内存超出maxmemory限制的时候, Redis提供了可供选择的几种策略

* noeviction	不继续服务写请求, 支持读请求
* allkeys-lru     在键空间中，移除最近最少使用的key
* allkeys-random 在键空间中，随机移除某个key
* volitale-lru  在设置了过期时间的键空间中，移除最近最少使用的key
* volitale-random 在设置了过期时间的键空间中，随机移除某个key
* volitale-ttl 在设置了过期时间的键空间中，有更早过期时间的key优先移除

LRU算法

* 链表元素的排列顺序就是元素的最近被访问的时间顺序
* 当字典某个元素被访问的时候, 它在链表中的位置会被放到表头.
* 位于链表尾部的元素就是不被重用的元素, 所以会被踢掉.

## Redis 集群

* 主从复制

  复制功能分为同步和命令传播两步.

  从服务器向主服务器发送SLAVEOF和PSYNC完成主从关系建立和主从复制.从节点刚刚加入集群的时候,必须进行一次完整重同步,再进行部分重同步.

  PSYNC有两种同步模式

  * 完整重同步
    * 快照同步(主服务器RDB文件落磁盘)
    * 无盘复制 (主服务器不落磁盘, 直接通过套接字将快照内容发送到从节点,从节点仍旧先将内容落入磁盘,然后一次性加载)
  * 部分重同步
    * 主服务器的复制偏移量和从服务器的复制偏移量
    * 主服务器复制积压缓冲区(固定长度的先进先出的FIFO队列, 默认大小为1MB)
    * 服务器的运行ID
      * 从服务器保存的运行ID同原来一致, 主服务器则进行部分重同步
      * 从服务器保存的运行ID不一致,主服务器则进行完整重同步

  复制的步骤

  * SLAVEOF 设置主服务器的地址和端口
  * 建立套接字连接
  * 发送PING命令
  * 身份验证
  * 发送端口信息
  * 同步
  * 命令传播

* Redis-Sentinel

  * 集群监控: 监控主节点和从节点是否正常工作
  * 消息通知:  如果有一个redis实例挂掉, 则会通知其他哨兵
  * 故障转移:  如果主节点挂掉, 会选举从节点为新的主节点
  * 配置中心: 如果发生了故障转移, 则通知客户端新的主节点地址

  哨兵最少需要3个实例来保证自己的健壮性

  Redis-Sentinel + 主从架构不保证消息丢失, 只能保证Redis集群的高可用性

* Redis-Cluster

  * Codis

    * 利用分片将特定的key转发到特定的实例

      ~~~python
      hash = crc32(command.key)
      slot_index = hash % slot_size // slot_size 槽位大小 默认1024
      redis = slots[slot_index].redis
      redis.do(command)
      ~~~

    * 槽位关系同步 利用zookeeper存储槽位关系, 并同步相关信息

    * 扩容

      ~~~python
      slot_index = crc32(command.key) % slot_size
      if slot_index in migrating_slots:
      	do_migrate_key(command.key)
      	redis = slots[slot_index].new_redis
      else:
      	redis = slots[slot_index].redis
      redis.do(command)
      ~~~

    * 自动均衡 会在系统比较空闲的时候观察每个Redis实例的slots数量, 如果不平衡,则会自动进行迁移

    * 代价

      * 无法支持事务
      * key的value值不建议太大, 1MB为佳,否则迁移会带来卡顿
      * Proxy中间层带来性能损耗, 可以通过增加多个Proxy实例来弥补

  * Redis-Cluster

    将所有数据划分为**16384**个槽位, 每个节点负责其中一部分槽位.

    客户端连接集群时,可以得到一份集群的槽位配置信息,直接定位到目标节点.

    每个节点会将集群的配置信息持久化到配置文件中, 配置文件必须可写.

    * 槽位定位

      ~~~python
      slot_index = crc16(key)%16384
      ~~~

    * 跳转

      当客户端向一个错误的节点发送指令后, 节点发现该键所在的槽并非由自己处理的时,向客户端返回一个MOVED错误,指引客户端转向至正在负责的槽的节点.

      ~~~python
      MOVED slot ip:port
      ~~~

    * 迁移

      重新分片可以在线进行,分片迁移的单位是槽, 迁移的槽在源节点的状态是migrating.在重新分片的过程中,集群不需要下线,并且源节点和目标节点都可以正常处理请求.

      迁移操作是个同步操作.迁移过程中, 如果每个key的内容都很小,就不会影响客户端的正常访问.但是如果key的内容很大, 会同时导致源节点和目标节点的卡顿,业务逻辑上应该避免产生大可以.

    * ASK错误

      在迁移过程中可能会出现MOVED和ASK错误

      对于MOVED错误来说, 槽的负责权已经从一个节点转移到另外一个节点.客户端后续的每次请求都可以直接转向MOVED的返回节点

      对于ASK错误而言, 只是两个节点在槽位迁移过程中的一种保护措施.客户端只会在接下来一次命令请求中去请求ASK错误返回的节点,而对后续命令请求没有影响,除非再次遇到ASK错误.

    * 复制与故障转移

      集群中的主节点负责处理槽,从节点负责复制主节点.当主节点发生故障的时候, 集群会自动将其中某个从节点上升为主节点,如果主节点没有从节点,则集群将处于完全不可用状态.

    * 可能下线与确定下线

      Redis集群节点采用Gossip协议来广播自己的状态以及对整个集群的认知

      某个节点发现一个节点失联了(Possible Fail),则将这条消息向集群广播,其他节点就可以收到这个节点的失联信息.如果已经收到了某个节点失恋的节点数量达到了集群的大多数,就可以将该节点标记为确定下线了状态，然后向整个集群广播,强迫其他节点接受该节点下线的事实并对该失联节点进行主从切换.

